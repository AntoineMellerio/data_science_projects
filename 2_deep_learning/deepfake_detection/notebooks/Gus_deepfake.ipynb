{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa2b1f7-e1eb-48ca-acff-81768bd9065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d5b08b-d92b-437d-998f-c88a202c8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7293e69-d7bc-43f2-8c90-8efcdded7ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/jovyan/hfactory_magic_folders/tooling_for_the_data_scientist/deepfakes_detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ac363-d48a-4d1d-a9c7-15ba66fd0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a78ca3-9f84-467f-81bd-459b45014aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21ece7-8061-4122-90fc-c54d855cc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(path + 'sample_submission.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592f0d4-1687-4599-889c-7d67080c8f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['image_id'] == '00059efd-9bd6-4493-9b0b-c6d7fafa4be2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c4a5e-0124-4cdc-86eb-a280f7da3c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "'00059efd-9bd6-4493-9b0b-c6d7fafa4be2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b740e27-6973-479a-97a9-5740d76b55a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'0007258f-1fa9-4b40-b663-f0eeed90acc5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c11a340-4dc5-4f27-b8be-cebb450276cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['image_id'] == '00059efd-9bd6-4493-9b0b-c6d7fafa4be2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e280dc5-a8d0-48d5-bcb4-73238265761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape[0] + test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939bf7a-f6ab-4f35-9dbd-6bf8dd981550",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread(\"hfactory_magic_folders/tooling_for_the_data_scientist/deepfakes_detection/images/\"+train.loc[0,'image_id']+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575460fd-1ef5-45ed-a592-fe3514fa8842",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for cur,i in enumerate(train.index[0:25]):\n",
    "    plt.subplot(5,5,cur+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    \n",
    "    plt.imshow(cv2.imread(path + \"/images/\"+train.loc[i,'image_id']+\".jpg\"))\n",
    "    \n",
    "    plt.xlabel(train.loc[i,\"label\"])\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd03f513-f89d-41b3-a294-1d157fc0f6e0",
   "metadata": {},
   "source": [
    "image_id = train['image_id'][0]\n",
    "\n",
    "im = Image.open(path + 'images/' + image_id + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc18c4-7eff-406d-a07a-8b81bdb04ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[train['label'] == 0].image_id"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98bc4ce1-bcd6-4bee-92e8-7229d64ee50e",
   "metadata": {},
   "source": [
    "for image_id in tqdm(train[train['label'] == 0].image_id):\n",
    "    im = Image.open(path + 'images/' + image_id + '.jpg')\n",
    "    im.save(f'train_images/real/{image_id}.jpg')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1f746fe-6172-4fe1-a2fc-b8c9746c34e4",
   "metadata": {},
   "source": [
    "for image_id in tqdm(train[train['label'] == 1].image_id):\n",
    "    im = Image.open(path + 'images/' + image_id + '.jpg')\n",
    "    im.save(f'train_images/fake/{image_id}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25213fc-d854-4b31-a967-a7e5d5e8321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256, 256)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"train_images\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"train_images\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2305ce-87b0-47c3-a841-d66c3d15ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b631c-ab0f-44c2-8549-894ec5d25105",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (None, 256, 256)\n",
    "\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "# x = data_augmentation(inputs)\n",
    "x = layers.experimental.preprocessing.Rescaling(scale=1./255)(inputs)\n",
    "train_ds = train_ds.prefetch(buffer_size=32)\n",
    "val_ds = val_ds.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6588c-8733-4fe1-901e-633af9afa489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    # x = data_augmentation(inputs)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd1b02-dde2-4d52-af47-7d5830447362",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e41cd87-fd91-4551-b4a6-d865fb08385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds.take(10), epochs=epochs, callbacks=callbacks, validation_data=val_ds.take(3),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ceb87730-9679-439b-ae68-d13360b27e73",
   "metadata": {},
   "source": [
    "epochs = 2\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
